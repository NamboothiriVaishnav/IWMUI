<div>
    <div class="row">
        <h2>Overview</h2>
        <p class="text-justify">Today`s increased level of automation in manufacturing also demands automation of material quality inspection with little human intervention. The trend is to reach human level accuracy or more in quality inspection with automation. To stay competitive, modern Industrial firms strive to achieve both quantity and quality with automation without compromising one over the other.
            To meet industry standards quality inspectors in manufacturing firms, inspect product quality usually after the product is manufactured, AI can be used to inspect products at various stages of the manufacturing process to ensure they meet quality standards. And also, AI can be used to optimize various manufacturing processes, such as casting and forging, to improve efficiency and reduce costs.
            </p>
    </div>

    <div class="row">
        <div class="col-sm-6">
            <div class="card">
                <div class="card-header">
                    Deep Learning Algorithms
                </div>
                <div class="card-body">
                    <ul class="card-text">
                        <li>EfficientNet</li>
                       
                    </ul>
                </div>
            </div>
        </div>
        <div class="col-sm-6">
            <div class="card">
                <div class="card-header">
                    Framework
                </div>
                <div class="card-body">
                    <ul class="card-text">
                        <li>Tensorflow  </li>
                        <li>Keras  </li>   
                    </ul>
                </div>
            </div>
        </div>
    </div>
    <br>

    <div class="row">
        <h2>Datasets used </h2>
        <!-- <p class="text-danger">
            Credit: - Open Lab on Human-Robot Interaction of Peking University.
        </p> -->
        <div>
            Processor datasets containing 3 types of defects and one good type, photoshoped, a graphics editor published by Adobe Systems. The defects defined in the dataset are Bend_pin, Missing_pin, Short_pins and Good pins. This synthetic Processor dataset contains 564 images with 3 defects and good or normal image. 57 images are used for testing a model.

        </div> 
    </div> <br>
    
    <div class="row">
        <h2>Model Hub</h2>
       <h5> EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h5>
        <p >
            EfficientNet is a family of convolutional neural network architectures that were designed to achieve state-of-the-art performance while being computationally efficient. The EfficientNet architecture was proposed in a 2019 paper by Mingxing Tan and Quoc Le from Google Brain.
           The EfficientNet architecture is based on a compound scaling method that uniformly scales the network width, depth, and resolution with a set of scaling coefficients. This allows the architecture to be optimized for different resource constraints, ranging from mobile devices to high-end servers. The scaling method is based on the observation that increasing one dimension of the network requires a proportional increase in the other dimensions in order to maintain a good balance between the network's representational capacity and computational efficiency.
           EfficientNet consists of several versions, labeled from EfficientNet-B0 to EfficientNet-B8, with increasing computational complexity and performance. EfficientNet-B0 is the smallest and most computationally efficient version, while EfficientNet-B8 is the largest and most powerful version. The architecture of EfficientNet includes multiple layers of convolutional, pooling, and activation functions, as well as a global average pooling layer and a fully connected output layer.
            The EfficientNet architecture has achieved state-of-the-art performance on several image classification benchmarks, while requiring fewer computational resources than competing models. It has also been shown to be effective for other computer vision tasks, such as object detection and semantic segmentation.
           
        </p>
    </div>
    <br>

    <div class="row">
        <h4>Process of Training Image classification Model.</h4>
        <p>The process of training an image classification model typically involves the following steps:
        </p>
        <h3>Data Preparation: </h3>
        <p>
            Collect and prepare the dataset for training. This includes data labeling, data cleaning, data augmentation, and data normalization.
        </p>
        <h3>Model Selection:  </h3>
        <p>
            Choose a suitable pre-trained model or build a custom model architecture based on the problem requirements.        </p>
        <h3>Model Compilation:  </h3>
        <p>
            Define the objective function, optimizer, and evaluation metrics to be used during the training process.
                </p>
        <h3>Model Training:  </h3>
        <p>
            Train the model on the prepared dataset. This involves feeding the data to the model, computing the loss, and updating the model parameters using backpropagation.
                </p>
        <h3>Model Evaluation:  </h3>
        <p>
            Evaluate the model's performance on a validation set. This involves computing metrics such as accuracy, precision, recall, and F1 score.
        </p>
        <h3>Hyperparameter Tuning:   </h3>
        <p>
        Fine-tune the model hyperparameters, such as learning rate, batch size, and number of epochs, to optimize the model performance. 
        </p>
        <h3>Model Deployment:   </h3>
        <p>
            Once the model is trained and evaluated, it can be deployed for inference on new data. This may involve integrating the model into a web application, mobile app, or other production system.
        </p>
        <br>
        <p>Throughout the training process, it is important to monitor the model performance and make adjustments as needed. This may include adjusting the training parameters, modifying the model architecture, or collecting more data. With careful preparation, training, and evaluation, it is possible to develop an accurate image classification model that can be used for a wide range of computer vision tasks.</p>

    </div>
    <div class="row">
        
        <h2>Installing Required Libraries</h2>
        <p> pip install -r C:\Users\Rajesh.Mandal\Downloads\democheck\demoprocessor\requirements.txt</p>
        <h2>Train and hyper-tune the model.</h2>
        <p>model.fit(train_generator, validation_data=validation_generator, epochs=epochs, batch_size=bs,steps_per_epoch=len(train_generator), validation_steps=len(validation_generator))</p>

    </div>


    <div class="row">
        <h4>Model Backbone:</h4>
        <p>Model Neck is mainly used to generate feature pyramids. Feature pyramids help models to generalize well on object 
           scaling. It helps to identify the same object with different sizes and scales. Feature pyramids are very useful
           and help models to perform well on unseen data. Other models use different types of feature pyramid techniques 
           like FPN, BiFPN, PANet, etc. in Yolo v5 PANet is used as a neck to get feature pyramids.
        </p>
    </div>

    <div class="row">
        <h4>Model Head:</h4>
        <p>The model Head is mainly used to perform the final detection part. It applied anchor boxes on
            features and generated final output vectors with class, probabilities, objectness, and bounding boxes. 
        </p>
    </div>

    <div class="row">
        <h4>Activation Function used in Yolo v5 model:</h4>
        <p>In Yolo v5 the Leaky Relu activation function is used in the middle/hidden layers and the sigmoid
           activation function is used in the final detection layer.
        </p>
    </div>

    <div class="row">
        <h4>Optimization Function:</h4>
        <p>For the optimization function in YOLO v5, we have two options.
        </p>
        <li>SGD</li>
        <li>Adam</li>
        <p>In YOLO v5, the default optimization function for training is SGD.
            However, you can change it to Adam by using the “—ada m” command-line argument.
            </p>
    </div>

    <div class="row">
        <h4>Cost Function or Loss Function:</h4>
        <p>In the Yolo family, there is compound loss is calculated based on the objectness score, class probability score,
           and bounding box regression score.Ultralytics have used Binary Cross-Entropy with the
        Logit Loss function from Pytorch to calculate the class probability and object score loss.
        </p>
    </div>
   

    <div class="row">
        <h2> Process of Training Object Detection Model using Yolov5  </h2>
        <h4>Prepare a custom dataset: </h4>
        <div >
            <div class="row">
            <li> Annotate the images using the labeling tool. </li>
            <img src="assets/modelHubImageFiles/DetectionModel.png" alt="" />
             </div> <br>
            <li> Convert the XML to .txt format.</li>
            <li>Split the datasets into train, test, and validation datasets.</li>
            <li>Create a custom.YAML file modifying the existing class according to our requirement and added more 
                classes to detect each defect
            </li>
            <pre>
                <code>
                    train: /content/drive/MyDrive/pcb_board/All_Defects/train  # train images (relative to 'path') 128 images
                    val: /content/drive/MyDrive/pcb_board/All_Defects/val  # val images (relative to 'path') 128 images
                    test: /content/drive/MyDrive/pcb_board/All_Defects/test  # test images (optional)
                     # class names
                     names: ['Soldering_Missing','mouse_bite','open_circuit','short','spur','spurious_copper']
                </code>
            </pre>
          
            <li>Installing Required Libraries</li>
            <pre>
                <code>
                    !pip install -r /content/drive/MyDrive/yolov5/requirements.txt
                </code>
            </pre>
            <li>Train and hyper-tune the model.</li>
            <pre>
                <code>
                     
                !python train.py --img 640 --batch 8 --epochs 150 --data custom.yaml --weights /content/drive/MyDrive/yolov5/runs/train/exp/weights/last.pt
                </code>
            </pre>

            <li>Check the training graph.</li>
            <pre>
                <code>
                    # logs save in the folder "runs"
                     %load_ext tensorboard
                     %tensorboard --logdir runs/train
                </code>
            </pre>
        </div>
    </div> <br>

    <div class="row">
        <h4>Metrics Graph </h4>
        <img src="assets/modelHubImageFiles/MetricsGraph.png" alt="" />
        <h4>Train Graph </h4>
        <img src="assets/modelHubImageFiles/TrainGraph.png" alt="" />
        <h4>Validation_Graph </h4>
        <img src="assets/modelHubImageFiles/ValidationGraph.png" alt="" />
        <img src="assets/modelHubImageFiles/Validation.png" alt="" />
        <img src="assets/modelHubImageFiles/PrecesionCurve.png" alt="" />
    </div>
    <li>Test the model.</li>
    <pre>
        <code>
            !python detect.py --weights /content/drive/MyDrive/yolov5/runs/train/exp/weights/best_100epoch.
            pt --source /content/drive/MyDrive/pcb_board/All_Defects/new_test
        </code>
    </pre>
   <div class="row">
    <li>Model Prdection</li>
    <img src="assets/modelHubImageFiles/ModelPredection.png" alt="" /> <br>
    <img src="assets/modelHubImageFiles/ModelPredection2.jpg" alt="" />
</div>

</div>